---
title: "Planning by Numbers Assignment 3 - CATEGORICAL DATA MODELS"
author: "Oliver Atwood & Charlie Townsley"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: flatly
    highlight: kate
    code_folding: hide
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
rm(list=ls())
```

```{r colors, include=FALSE}
#set colors
palette <- c("#a02300", "#0059c7", "#6496b4", "#E1B93C")
#red and gold are accent
#blue is chart
#dark blue is outline
```


# Part A
>Oliver

>The dataset, Chester Urban Growth
(‘Chester_Urban_Growth.csv’ in ‘Datasets’ folder on Canvas. For metadata on this csv, see
the .xlsx file) includes selected GIS-derived land cover, land use, transportation facility, and
demographic data for Chester County, PA for 1992 and 2001. Each row in the dataset
corresponds to a 500-meter raster cell location.

```{r part A packages and data, warning = FALSE, message = FALSE}
#install packages
#only run once


#run every session
library(tidyverse)
library(dplyr)
library(ggplot2)
library(caret)
library(MASS)
library(corrplot)
library(magrittr)

Dat_A <- read_csv("https://raw.githubusercontent.com/c-townsley/pbn_a3_repo/main/Data/Chester_Urban_Growth.csv")
```

<br>

## A.1
>Read the data into R. Run descriptive statistics as necessary.

```{r packages data and colors, warning = FALSE, message = FALSE}
summary(Dat_A)
```

<br>

## A.2
>Create a new binary (0/1) variable, [CHNG_URB] indicating those raster cells that were
either farmland or pasture land or forest in 1992, and which converted to urban uses by
2001. Indicate these cells with a 1. All other cells should be coded to 0.

```{r Land Use Change Characterization}
Dat_A <- Dat_A %>% 
  mutate(CHNG_URB = ifelse(FARM92 == 1 | PASTURE92 == 1 | FOREST92 == 1 & URBAN01 == 1, 1, 0))

```
<br>

## A.3
>Build a best “lean & mean” binomial logit model that identifies the determinants of
agricultural/pasture/forest land-to-urban land use change between 1992 and 2001 (This
is the 0/1 variable created in step 2). Use whatever independent variables you think
appropriate, and be sure to explain your logic and model development steps.

```{r Correlations with Land Use Change}
print("SLOPE")
cor(Dat_A$CHNG_URB, Dat_A$SLOPE, use="complete.obs", method="pearson")
print("FOURLNE300")
cor(Dat_A$CHNG_URB, Dat_A$FOURLNE300, use="complete.obs", method="pearson")
print("INTERST800")
cor(Dat_A$CHNG_URB, Dat_A$INTERST800, use="complete.obs", method="pearson")
print("REGRAIL300")
cor(Dat_A$CHNG_URB, Dat_A$REGRAIL300, use="complete.obs", method="pearson")
print("PARKS500M")
cor(Dat_A$CHNG_URB, Dat_A$PARKS500M, use="complete.obs", method="pearson")
print("WATER100")
cor(Dat_A$CHNG_URB, Dat_A$WATER100, use="complete.obs", method="pearson")
print("CITBORO_10")
cor(Dat_A$CHNG_URB, Dat_A$CITBORO_10, use="complete.obs", method="pearson")
print("DIST_WATER")
cor(Dat_A$CHNG_URB, Dat_A$DIST_WATER, use="complete.obs", method="pearson")
print("DIST_RAILS")
cor(Dat_A$CHNG_URB, Dat_A$DIST_RAILS, use="complete.obs", method="pearson")
print("DIST_REGRA")
cor(Dat_A$CHNG_URB, Dat_A$DIST_REGRA, use="complete.obs", method="pearson")
print("DIST_PASSR")
cor(Dat_A$CHNG_URB, Dat_A$DIST_PASSR, use="complete.obs", method="pearson")
print("DIST_4LNE_")
cor(Dat_A$CHNG_URB, Dat_A$DIST_4LNE_, use="complete.obs", method="pearson")
print("DIST_INTER")
cor(Dat_A$CHNG_URB, Dat_A$DIST_INTER, use="complete.obs", method="pearson")
print("DIST_PARKS")
cor(Dat_A$CHNG_URB, Dat_A$DIST_PARKS, use="complete.obs", method="pearson")
print("PAL_WETLND")
cor(Dat_A$CHNG_URB, Dat_A$PAL_WETLND, use="complete.obs", method="pearson")
print("POPDEN90")
cor(Dat_A$CHNG_URB, Dat_A$POPDEN90, use="complete.obs", method="pearson")
print("MEDINC90")
cor(Dat_A$CHNG_URB, Dat_A$MEDINC90, use="complete.obs", method="pearson")
print("MEDHSEVAL_")
cor(Dat_A$CHNG_URB, Dat_A$MEDHSEVAL_, use="complete.obs", method="pearson")
print("PCT_WHITE_")
cor(Dat_A$CHNG_URB, Dat_A$PCT_WHITE_, use="complete.obs", method="pearson")
print("PCT_SFHOME")
cor(Dat_A$CHNG_URB, Dat_A$PCT_SFHOME, use="complete.obs", method="pearson")
print("PCT_POV_90")
cor(Dat_A$CHNG_URB, Dat_A$PCT_POV_90, use="complete.obs", method="pearson")
print("PCT_HSB_19")
cor(Dat_A$CHNG_URB, Dat_A$PCT_HSB_19, use="complete.obs", method="pearson")
print("PCT_COLGRD")
cor(Dat_A$CHNG_URB, Dat_A$PCT_COLGRD, use="complete.obs", method="pearson")
```
The variables in order of correlation with CHNG_URB are as follows:
"DIST_INTER" 0.3188977
"DIST_REGRA" 0.2908341
"DIST_RAILS" 0.290569
"SLOPE" -0.2689929
"DIST_PARKS" 0.2504532
"REGRAIL300" -0.2117686
"INTERST800" -0.2075421
"MEDHSEVAL_" -0.1595283
"MEDINC90" -0.1479734
"PCT_POV_90" 0.115068
"PCT_COLGRD" 0.115068
"DIST_WATER" -0.09334977
"PCT_WHITE_" -0.08178655
"DIST_PASSR" 0.0765004
"PARKS500M" -0.07496059
"PCT_HSB_19" 0.07437706
"POPDEN90" -0.07412875
"DIST_4LNE_" 0.07289739
"FOURLNE300" -0.05593594
"PCT_SFHOME" -0.0524793
"CITBORO_10" -0.03061511
"WATER100" -0.01852956
"PAL_WETLND" -0.007407224

Let's test the top 10 variables mos correlated with CHNG_URB for colinearity using a cor plot.
```{r correlation matrix, fig.width=7, fig.height=5, fig.width=8}
#make matrix of variables we're testing
mod_vars <- Dat_A %>% 
  dplyr::select(CHNG_URB, DIST_INTER, DIST_REGRA, DIST_RAILS, SLOPE, DIST_PARKS, REGRAIL300, INTERST800, MEDHSEVAL_, MEDINC90, PCT_POV_90)

#compute correlation matrix
cormatrix <- cor(mod_vars) %>% 
  round(., 2)

#plot a correlogram
corrplot(cormatrix, method = "circle", type = "lower", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```

This plot shows that the following variables exhibit correlation with each other, meaning that their inclusion in the model is mutually exclusive.

DIST_INTER & DIST_REGRA & DIST_RAILS
DIST_INTER & INTERST800
MEDHSEVAL_ & MEDINC09

```{r Binomial Logit Model 1}
mod1 <- glm (CHNG_URB ~ DIST_REGRA + SLOPE + DIST_PARKS + REGRAIL300 + INTERST800 + MEDHSEVAL_ + PCT_POV_90, data=Dat_A, family = binomial)
summary(mod1)
```
PCT_POV_90 appears to be insignificant, so let's try removing it from model 2
```{r Binomial Logit Model 2}
mod2<- glm (CHNG_URB ~ DIST_REGRA + SLOPE + DIST_PARKS + REGRAIL300 + INTERST800 + MEDHSEVAL_, data=Dat_A, family = binomial)
summary(mod2)
```
When we remove PCT_POV_90, the AIC decreases by 0.2. INTERST800 also appears to be insignificant, so what happens if we remove that too?

```{r Binomial Logit Model 3}
mod3<- glm (CHNG_URB ~ DIST_REGRA + SLOPE + DIST_PARKS + REGRAIL300 + MEDHSEVAL_, data=Dat_A, family = binomial)
summary(mod3)
```
Now the AIC is back to where it was in the first model. Also, the residual deviance is 0.2 higher than model 2.

Since DIST_INTER is colinear with DIST_REGRA, DIST_RAILS, and INTERST800, it was not included in the first version of the model, so let's try a model with DIST_INTER.

```{r Binomial Logit Model 4}
mod4<- glm (CHNG_URB ~ DIST_INTER + SLOPE + DIST_PARKS + REGRAIL300 + MEDHSEVAL_, data=Dat_A, family = binomial)
summary(mod4)
```
The AIC increased on this model compared to the previous ones, so it seems like model 2 is the way to go.

```{r Binomial Logit Model 2}
##################################
# CALCULATE PREDICTION ACCURACY
##################################

#####model1
#calc the predicted probabilities based on the model
pred <- as.data.frame(fitted(mod1))
pred <- rename(pred, "prob" = "fitted(mod1)")
pred <- mutate(pred, "binary" = ifelse(prob < 0.5, 0, 1))
#append column to original data frame
Dat_A$binary <- pred$binary
head(Dat_A)
#calculate accuracy rate
mod1_Acc <- (sum(Dat_A$URBAN01 == 1 & Dat_A$binary == 1) + sum(Dat_A$URBAN01 == 0 & Dat_A$binary == 0)) / nrow(Dat_A)


#####model2
#calc the predicted probabilities based on the model
pred <- as.data.frame(fitted(mod2))
pred <- rename(pred, "prob" = "fitted(mod2)")
pred <- mutate(pred, "binary" = ifelse(prob < 0.5, 0, 1))
#append column to original data frame
Dat_A$binary <- pred$binary
head(Dat_A)
#calculate accuracy rate
mod2_Acc <- (sum(Dat_A$URBAN01 == 1 & Dat_A$binary == 1) + sum(Dat_A$URBAN01 == 0 & Dat_A$binary == 0)) / nrow(Dat_A)


#####model3 
#calc the predicted probabilities based on the model
pred <- as.data.frame(fitted(mod3))
pred <- rename(pred, "prob" = "fitted(mod3)")
pred <- mutate(pred, "binary" = ifelse(prob < 0.5, 0, 1))
#append column to original data frame
Dat_A$binary <- pred$binary
head(Dat_A)
#calculate accuracy rate
mod3_Acc <- (sum(Dat_A$URBAN01 == 1 & Dat_A$binary == 1) + sum(Dat_A$URBAN01 == 0 & Dat_A$binary == 0)) / nrow(Dat_A)


#####model4
#calc the predicted probabilities based on the model
pred <- as.data.frame(fitted(mod4))
pred <- rename(pred, "prob" = "fitted(mod4)")
pred <- mutate(pred, "binary" = ifelse(prob < 0.5, 0, 1))
#append column to original data frame
Dat_A$binary <- pred$binary
head(Dat_A)
#calculate accuracy rate
mod4_Acc <- (sum(Dat_A$URBAN01 == 1 & Dat_A$binary == 1) + sum(Dat_A$URBAN01 == 0 & Dat_A$binary == 0)) / nrow(Dat_A)

print("model 1 Accuracy")
mod1_Acc
print("model 2 Accuracy")
mod2_Acc
print("model 3 Accuracy")
mod3_Acc
print("model 4 Accuracy")
mod4_Acc
```
<br>

Let's try this another way. What happens if we let the machine do the work of sorting out which variables to include in the model?
```{r ML_Model1 training}
Dat_B <- Dat_A %>% dplyr::select(-CHESCO, -X, -Y, -PCT_COLGRD, -binary)

set.seed(3456)
trainIndex <- createDataPartition(Dat_B$DIST_INTER, p = .70, list = FALSE, times = 1)

Dat_B_Train <- Dat_B[ trainIndex,]
Dat_B_Test  <- Dat_B[-trainIndex,]

ML_Model1 <- glm(CHNG_URB ~ ., family="binomial"(link="logit"), data = Dat_B_Train)
summary(ML_Model1)
```
This looks wack.

Train another model, this time removing the variables we know are colinear.
```{r ML_Model2 training}
Dat_C <- Dat_B %>% dplyr::select(-DIST_REGRA, -DIST_RAILS, -INTERST800, -MEDINC90)

set.seed(3456)
trainIndex2 <- createDataPartition(Dat_C$DIST_INTER, p = .70, list = FALSE, times = 1)

Dat_C_Train <- Dat_C[ trainIndex,]
Dat_C_Test  <- Dat_C[-trainIndex,]

ML_Model2 <- glm(CHNG_URB ~ ., family="binomial"(link="logit"), data = Dat_C_Train)
summary(ML_Model2)
```

DIST_INTER & DIST_REGRA & DIST_RAILS
DIST_INTER & INTERST800
MEDHSEVAL_ & MEDINC09


```{r confusion_matrix, message = FALSE, warning = FALSE}
classProbs <- predict(ML_Model2, Dat_C_Test, type="response")

testProbs <- data.frame(obs = as.numeric(Dat_C_Test$CHNG_URB), pred = classProbs)

testProbs$predClass  = ifelse(testProbs$pred > .5 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass), 
                       positive = "1")
```
Okay, so according to this confusion matrix, this model is 100% accurate. We may have an issue with over-fitness here, but it's certainly better than our manually developed model, which had an accuracy rate of 42%.


<br>

## A.4
>Explain the results of your best model in a few paragraphs for non-statisticians. How
well does your model fit the data? Which factors are most important in explaining land
use change in Chester County from 1992-2001? How do you know? Do you have any
ideas for improving the performance of your model?



<br>

## A.5
>Include a few plots or tables that show the probabilities versus changes in key variables
in your model.



<br>
<br>

# Part B
>Charlie
>How do a person’s household, demographic, and trip characteristics
affect their choice of transportation mode to work? To answer this
question, we will use data from the DVRPC HHTS.

```{r part B packages and data, warning = FALSE, message = FALSE}
#install packages
#only run once


#run every session
library(tidyverse)
library(dplyr)
library(ggplot2)

per_dat <- read_csv("https://raw.githubusercontent.com/c-townsley/pbn_a3_repo/main/Data/HH%20Travel%20Survey/per_pub.csv")

trip_dat <- read_csv("https://raw.githubusercontent.com/c-townsley/pbn_a3_repo/main/Data/HH%20Travel%20Survey/trip_pub.csv")

hh_dat <- read_csv("https://raw.githubusercontent.com/c-townsley/pbn_a3_repo/main/Data/HH%20Travel%20Survey/hh_pub_CSV.csv", col_names = TRUE)
```

<br>

# B.1
>Develop the best (“leanest and meanest” and unbiased) binomial LOGIT model you
can explaining whether a commuter drove to work or used another mode. Use any
and all independent variables you think appropriate, including dummy variables.

```{r binomial logit 1}

```


>Summarize your model results in a paragraph.

>Include a few plots or tables that show the probabilities of each choice versus changes in key variables in your model.

>NOTE: THIS MAY REQUIRE YOU TO LOOK THROUGH THE META_DATA. It requires
selecting the observations from the trip table that correspond to a person’s work trip. A
person may have multiple work trips – how will you handle this? (I suggest taking the first
one-way work trip of the day, but there are others methods to handle this).

<br>

# B.2
>Develop a second binomial LOGIT model explaining whether a commuter
walked/biked to work or used another mode. Use any and all independent variables
you think appropriate, including dummy variables.

>Summarize your model results in a few paragraphs. Include a few plots or tables
that show the probabilities of each choice versus changes in key variables in your
model.

>How does this model compare to the results of the models from question B1?
Venture some reasons for the differences.

<br>

# B.3
>Develop the best (“leanest and meanest” and unbiased) multi-nomial LOGIT model
you can explaining whether a traveler drove to work, carpooled, took public transit,
or walked or biked. Use any and all independent variables you think appropriate,
including dummy variables.

>Summarize your model results in a few paragraphs. Include a few plots or tables
that show the probabilities of each choice versus changes in key variables in your
model.

>How well does your model predict observed mode choices? For which modes
does it perform best? Worst? How do you know?

>What ideas do you have for additional variables (that are not available in the
data) that might make for better models?

